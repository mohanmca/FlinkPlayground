## Select but partition by customer
select customer_id, count(*) from orders
group by customer_id

* Every group by is partition
* Dynamic table === stream
* Continuous query on dynamic table == continuous query on stream

Got it — I’ll **parse and condense this into study-ready notes**, preserving **every factual point**, but removing repetition and narrative fluff.
Below is a **clean, hierarchical summary** you can revise from directly.

---

## 1. What Flink SQL Is

* **Flink SQL**

  * Based on the **SQL standard**
  * Uses familiar abstractions:

    * Tables
    * Catalogs
  * Provides **strong correctness guarantees**
  * Is an **API for building Flink applications**
  * Closely resembles SQL databases in concepts, but **is not a database**

* **Best entry point into Apache Flink**

  * Especially for users coming from SQL/database backgrounds

## 2.3 Sample tables and Queries

* Databases store data in **tables**
* Tables:

  * Have names (e.g., `orders`)
  * Contain rows
  * Columns have:

    * Names
    * Data types

**Example `orders` table columns:**

* order_id
* customer_id
* price
* order_time

**Example queries:**

* Count total orders → scans entire table
* Group by customer → counts per customer

These are:

* **Batch-oriented**
* **Brute-force scans**
* Touch all relevant data each time

---

## 3. Database Internals

### 3.1 Query Processor (Core Component)

* Responsible for receiving queries and producing results
* Has **two phases**:

#### 1. Planning Phase

* Parses SQL
* Compiles query into an **execution plan**
* Requires metadata about:

  * Tables
  * Functions
  * Database objects
* Metadata is stored in the **catalog**

#### 2. Execution Phase

* Executes the plan
* Requires access to data storage
* Handled by the **storage engine**

---

## 4. Views and Materialized Views

### 4.1 Views

* Query results can be treated as **logical tables**
* Used to:

  * Decompose complex queries
  * Avoid storing intermediate results physically

---

### 4.2 Materialized Views

* Like views, but results are **physically stored**
* Acts as a **cache**
* Useful when:

  * Queries are reused frequently

---

### 4.3 Materialized View Maintenance Strategies

#### 1. Complete Refresh

* Re-executes full query after each update
* Simple but expensive
* Still useful if:

  * Reads >> writes

#### 2. Incremental Update

* View is updated **only for changed data**
* Initial creation uses complete refresh
* Subsequent updates:

  * Combine base-table changes with previous view state
* Much more efficient for large tables
* Complex to implement
* Few databases support it
* Often comes with limitations

---

## 5. Flink SQL Core Model

### 5.1 Continuous Queries on Dynamic Tables

* Flink SQL executes:

  * **Continuous queries**
  * On **streams / dynamic tables**
* Conceptually similar to:

  * Incremental materialized views

---

### 5.2 Streaming Mode Behavior

* Query describes a **continuous process**
* Example:

  * Counting orders per customer from an **unbounded stream**
* Flink:

  * Compiles SQL into a **Flink job**
  * Executes it in a cluster
  * Streams events through the job

---

### 5.3 Changelog Streams

* Flink SQL:

  * Consumes streams
  * Produces streams
* These streams are generally **changelog streams**

**Example behavior:**

* First event → emits an INSERT
* Subsequent event for same key → emits:

  * RETRACTION
  * UPDATE

---

## 6. State in Flink SQL

* Flink **does not maintain materialized views**

* Instead:

  * Maintains **state**
  * Stored in a **distributed key/value store**

* Runtime is optimized to:

  * Store **minimal state**
  * Still produce correct results

* For grouped aggregations:

  * State ≈ what a materialized view would store

* For other queries:

  * Flink may store **less state**

---

## 7. Why Flink Always Uses Incremental Updates

* Complete refresh would require:

  * Re-ingesting entire stream per event (impossible)
  * Or mirroring all input data into Flink state (unworkable)
* Therefore:

  * **Flink SQL always uses incremental updates**

---

## 9. Confluent Catalog and Storage in Flink

* Both are **pluggable**

**In Confluent Cloud:**
* Catalog → **Schema Registry**
* Storage layer → **Kora**
* Cloud-native Kafka storage engine

---

## 10. Correctness Guarantees

### 10.1 Processing Guarantees

Flink SQL supports:

* **At-least-once**

  * Duplicates possible
* **Exactly-once**

  * No missing data
  * No duplicates
  * More precisely: **effectively exactly-once**

**Meaning:**

* Each event affects Flink-managed state **exactly once**

---

### 10.2 Requirements for Guarantees

* Both guarantees require:

  * **Rewindable/replayable sources**
* Exactly-once additionally requires:

  * **Transactional writes to sinks**

**Kafka or file systems** satisfy these requirements

---

### 10.3 Confluent Cloud Specifics

* Always capable of **exactly-once**
* Can choose **at-least-once** to:

  * Reduce latency
  * Configure Kafka consumers to not use `read-committed`

---

## 11. Exactly-Once vs ACID

* ACID provides something Flink lacks:

  * **Multi-key transactions**
  * Example: money transfer between accounts

* For **single-key operations**:

  * Flink + Kafka ≈ ACID database robustness

* Flink resembles a **distributed key/value store** internally

---

## 12. Batch vs Streaming in Flink SQL

### Batch Mode

* Query/response model
* Similar to databases
* Data stored externally:

  * Kafka
  * Data lakes

### Streaming Mode

* Continuous queries
* Streams in → streams out
* Streams may be **changelog streams**
* Inputs/outputs called **dynamic tables**

---

## 13. Scalability

* Flink SQL can maintain:

  * Exactly-once guarantees
  * At **hundreds or thousands of nodes**
* Traditional SQL databases:

  * Struggle with strict consistency at large scale

---

## 14. Primary Use Cases of Flink SQL

1. **Reactive, event-driven applications**

   * Fraud detection
   * Anomaly detection

2. **Reusable data products**

   * Cleaning
   * Enrichment
   * Schematization
   * Feeding:

     * Data lakes
     * Feature stores

---

## 15. Additional Resources

* Hands-on exercises available on **Confluent Developer**



## Reference
1. [What is Flink SQL? Is it a database?](https://developer.confluent.io/courses/flink-sql/flink-sql-vs-sql-databases/)